{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2mjw53RxIMe",
        "outputId": "a70779ba-4582-4d6c-e239-4169f01a21e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.11/dist-packages (1.4.5)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.13)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (18.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install together PyMuPDF tiktoken pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import tiktoken\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, chunk_size=1000):\n",
        "    \"\"\"Splits text into manageable chunks based on token limits.\"\"\"\n",
        "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # OpenAI tokenizer\n",
        "    tokens = tokenizer.encode(text)\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), chunk_size):\n",
        "        chunk = tokens[i:i+chunk_size]\n",
        "        chunks.append(tokenizer.decode(chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Extract and split PDF text\n",
        "pdf_path = \"/content/TNEA_Cutoff_Explanations.pdf\"\n",
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "text_chunks = chunk_text(extracted_text, chunk_size=1000)\n",
        "\n",
        "print(f\"PDF split into {len(text_chunks)} chunks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwZQOtunx1rX",
        "outputId": "00ab1ff3-56a8-4426-8e35-3066d6f5823d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF split into 287 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "college_data_chunks = {i: chunk for i, chunk in enumerate(text_chunks)}\n",
        "\n",
        "# Save for future use\n",
        "import pickle\n",
        "\n",
        "with open(\"college_data_chunks.pkl\", \"wb\") as f:\n",
        "    pickle.dump(college_data_chunks, f)\n",
        "\n",
        "print(\"College data saved in chunks for retrieval.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvmA_pIQl3am",
        "outputId": "df39ef01-67b1-42ef-c7c4-1e25d95ced77"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "College data saved in chunks for retrieval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from together import Together\n",
        "# import pickle\n",
        "\n",
        "# # Load the stored chunks\n",
        "# with open(\"college_data_chunks.pkl\", \"rb\") as f:\n",
        "#     college_data_chunks = pickle.load(f)\n",
        "\n",
        "# # Initialize API client\n",
        "# client = Together(api_key=\"b9503247fb87502846460e23685b040c0fb0f1a4a1221aee25d32b22217453fa\")\n",
        "\n",
        "# def retrieve_relevant_chunk(query):\n",
        "#     \"\"\"Find the most relevant chunk based on the user's query.\"\"\"\n",
        "#     relevant_chunks = []\n",
        "#     for chunk in college_data_chunks.values():\n",
        "#         if query.lower() in chunk.lower():\n",
        "#             relevant_chunks.append(chunk)\n",
        "\n",
        "#     return \" \".join(relevant_chunks[:3])  # Limit to 3 chunks\n",
        "\n",
        "# def query_college_cutoff(cutoff, department=\"COMPUTER SCIENCE AND ENGINEERING\", community=\"BC\"):\n",
        "#     \"\"\"Generate a dynamic query and retrieve relevant chunks.\"\"\"\n",
        "#     query = f\"Find colleges for department {department} and community {community} with a minimum cutoff of {cutoff}.\"\n",
        "#     relevant_data = retrieve_relevant_chunk(str(cutoff))  # Retrieve relevant data\n",
        "\n",
        "#     prompt = f\"\"\"\n",
        "#     You are an expert in Tamil Nadu Engineering Admissions (TNEA).\n",
        "#     Here is the relevant college cutoff data:\n",
        "#     {relevant_data}\n",
        "\n",
        "#     Now, answer the following query:\n",
        "#     {query}\n",
        "#     \"\"\"\n",
        "\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "#     )\n",
        "\n",
        "#     return response.choices[0].message.content\n",
        "\n",
        "# # Example query\n",
        "# user_cutoff = 199.5\n",
        "# result = query_college_cutoff(user_cutoff)\n",
        "# print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_SPA0Ihi0E1",
        "outputId": "867a95a9-2b5d-4bd2-d270-0900780b519a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided cutoff data, for the department \"COMPUTER SCIENCE AND ENGINEERING\" and community \"BC\" with a minimum cutoff of 199.5, there is no college that meets this criteria.\n",
            "\n",
            "The college with code 1, \"University Departments of Anna University Chennai - CEG Campus\", has a minimum cutoff of 200 for BC community, which is higher than the specified minimum cutoff of 199.5.\n",
            "\n",
            "The college with code 4, \"University Departments of Anna University Chennai - MIT Campus\", has a minimum cutoff of 198.5 for BC community, which is lower than the specified minimum cutoff of 199.5.\n",
            "\n",
            "Therefore, there are no colleges that meet the specified criteria.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from together import Together\n",
        "import pickle\n",
        "\n",
        "# Load stored chunks\n",
        "with open(\"college_data_chunks.pkl\", \"rb\") as f:\n",
        "    college_data_chunks = pickle.load(f)\n",
        "\n",
        "# Initialize API client\n",
        "client = Together(api_key=\"b9503247fb87502846460e23685b040c0fb0f1a4a1221aee25d32b22217453fa\")\n",
        "\n",
        "def retrieve_relevant_chunk(query):\n",
        "    \"\"\"Find the most relevant chunk based on the user's query.\"\"\"\n",
        "    relevant_chunks = []\n",
        "    for chunk in college_data_chunks.values():\n",
        "        if query.lower() in chunk.lower():\n",
        "            relevant_chunks.append(chunk)\n",
        "\n",
        "    return \" \".join(relevant_chunks[:3])  # Limit to 3 chunks\n",
        "\n",
        "def query_college_cutoff(cutoff, department=\"COMPUTER SCIENCE AND ENGINEERING\", community=\"BC\"):\n",
        "    \"\"\"Generate a dynamic query and retrieve relevant chunks.\"\"\"\n",
        "    query = f\"Find colleges for department {department} and community {community} with a minimum cutoff of {cutoff}.\"\n",
        "    relevant_data = retrieve_relevant_chunk(str(cutoff))  # Retrieve relevant data\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in Tamil Nadu Engineering Admissions (TNEA).\n",
        "    Here is the relevant college cutoff data:\n",
        "    {relevant_data}\n",
        "\n",
        "    Now, extract and return only the college details in JSON format:\n",
        "    [{{\n",
        "      \"college_code\": <College Code>,\n",
        "      \"college_name\": \"<College Name>\"\n",
        "    }}]\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "\n",
        "    # Check if response content is valid JSON before parsing\n",
        "    try:\n",
        "        json_result = json.loads(response.choices[0].message.content)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Invalid JSON response: {response.choices[0].message.content}\")\n",
        "        # Handle the error, e.g., return an empty list or a default value\n",
        "        return []  # or {}\n",
        "\n",
        "    return json.dumps(json_result, indent=2)  # Pretty print JSON\n",
        "\n",
        "# Example query\n",
        "user_cutoff = 199.5\n",
        "result = query_college_cutoff(user_cutoff)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BEQLFi9nfNR",
        "outputId": "8a792752-d452-4a8e-9820-8a7f2bb46e53"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Invalid JSON response: Here are the college details extracted from the given data in JSON format:\n",
            "\n",
            "```\n",
            "[\n",
            "  {\n",
            "    \"college_code\": 1,\n",
            "    \"college_name\": \"University Departments of Anna University Chennai - CEG Campus Sardar Patel Road Guindy Chennai 600 025\"\n",
            "  },\n",
            "  {\n",
            "    \"college_code\": 4,\n",
            "    \"college_name\": \"University Departments of Anna University Chennai - MIT Campus Chrompet Tambaram Taluk Chengalpattu District 600 044\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "[]\n"
          ]
        }
      ]
    }
  ]
}